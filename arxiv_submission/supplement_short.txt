\documentclass{article}

\usepackage[letterpaper,top=2cm,bottom=2cm,left=3cm,right=3cm,marginparwidth=1.75cm]{geometry}
\pdfoutput=1
\usepackage{amsmath, amsfonts, amssymb, mathtools}
\usepackage{accents}
\usepackage{graphicx}
\usepackage{algorithm}
\usepackage[noend]{algpseudocode}
\usepackage{amsthm}
\usepackage{bm}
\usepackage{cases}
\usepackage{caption}
\usepackage{soul}
\usepackage{tikz}
\usepackage{pgfplots}
\usepackage{float}
\usepackage{xr-hyper}
\usepackage{hyperref}
\externaldocument{alloscore-application-shorter}

\usepackage{enumitem}
\newlist{todolist}{itemize}{2}
\setlist[todolist]{label=$\square$}
\usepackage{pifont}
\newcommand{\cmark}{\ding{51}}%
\newcommand{\xmark}{\ding{55}}%
\newcommand{\done}{\rlap{$\square$}{\raisebox{2pt}{\large\hspace{1pt}\cmark}}%
\hspace{-2.5pt}}
\newcommand{\wontfix}{\rlap{$\square$}{\large\hspace{1pt}\xmark}}

\DeclareMathOperator*{\argmin}{argmin}
\DeclareMathOperator{\short}{sh}
\DeclareMathOperator{\Ex}{\mathbb{E}}


\usepackage{setspace}


\usepackage{parskip}

\usepackage{soul}
\usepackage{xcolor}
\def\elr#1{{\color{cyan}\textbf{ELR:[#1]}}}
\def\apg#1{{\color{red}\textbf{APG:[#1]}}}
\def\bwr#1{{\color{violet}\textbf{BWR:[#1]}}}
\def\ngr#1{{\color{blue}\textbf{NGR:[#1]}}}

\usepackage{natbib}
\bibliographystyle{unsrtnat}

\title{Supplementary Material for ``Evaluating infectious disease forecasts with allocation scoring rules''}
\author{Aaron Gerding, Nicholas G. Reich, Benjamin Rogers, Evan L. Ray}

\renewcommand{\thesection}{\Alph{section}}
\begin{document}

\newcommand{\del}[2]{\frac{\partial {#1} }{\partial {#2}} }
\newcommand{\dby}[2]{\frac{d {#1} }{d {#2}} }
\newcommand{\sbar}{\overline{s}}

\newtheorem{proposition}{Proposition}

\theoremstyle{remark}
\newtheorem*{remark}{Remark}

\maketitle

\tableofcontents

\section{Introduction to Supplement}
\label{sec:intro}

We address some technical and methodological points from the main text. We begin in section \ref{sec:proper} by defining proper scoring rules and showing that the allocation score is proper. In section \ref{sec:ex-shortage}, we formalize the concept of a \emph{shortage} of resources, give some key results about expected resource shortages under a distribution characterizing uncertainty about (future) levels of resource need, and illustrate how quantiles arise as the Bayes act in a decision making problem about the quantity of a resource to purchase. Section \ref{sec:bayes-quantiles} gives a justification for the result that the Bayes act for the allocation problem is given by a vector of quantiles of the forecast distributions in each location at a shared probability level, which was stated in section \ref{sec:methods.detailed.specific_allocation} of the main text. We describe the algorithm that we use to compute allocations given a forecast distribution in each location in section \ref{sec:numeric}. In section \ref{sec:distfromq}, we describe the methods for approximating a full distribution from a set of quantiles, implemented in the R package \verb`distfromq`, that we used to support computation of allocation scores from quantile forecasts that were submitted to the US COVID-19 Forecast Hub for the application in the main text. Finally, in section \ref{sec:propriety_of_parametric_approximation} we examine implications for propriety of an analysis that uses summaries of forecasts (such as predictive quantiles) rather than the full forecast distributions for computation of allocation scores.

\section{Proper scoring rules}
\label{sec:proper}

In decision theory, a loss function $l$ is used to formalize a decision problem by assigning numerical value $l(x,y)$ to the
\emph{result} of taking an \emph{action} $x$ in preparation for an \emph{outcome} $y$. A \emph{scoring rule} $S$ is a
loss function for a decision problem where the action is a probabilistic forecast $F$ of the outcome $y$ (or the statement of $F$ by a forecaster).
% As does any loss fun $S$ transforms a random outcome variable $Y$ into a random loss $S(F,Y)$.
We refer to the realized loss $S(F,y)$ as the \emph{score} of $F$ at $y$.

Probabilistic forecasts can be seen as a unique kind of action in that they can be used to generate their
own (simulated) outcome data, against which they can be scored using $S$. A probabilistic forecast
$F$ is thus committed to the ``self-assessment'' $\Ex_F [S(F, Y)] := \Ex [S(F, Y^F)]$, where $Y^F \sim F$ is the random variable defined
by sampling from $F$, as well to an assessment $\Ex_F [S(G, Y)]$ of any alternative forecast $G$.

A natural consistency criterion for $S$ is that, for observations assumed to be drawn from $F$, it will not assess any other forecast $G$
as being better than $F$ itself, that is, that
\begin{align}
\Ex_F [S(F, Y)] \leq \Ex_F [S(G, Y)] \label{eqn:prop_ineq}
\end{align}
for any $F,G$. A scoring rule meeting this criterion is called \emph{proper}. If $S$ were improper, then from the perspective of
a forecaster focussed (solely) on expected loss minimization, the decision to state
a forecast $G$ other than the forecast $F$ which they believe describes $Y$ could be superior to the decision to state $F$.
$S$ is \emph{strictly proper} when
\eqref{eqn:prop_ineq} is a strict inequality, in which case the
\emph{only} optimal decision for a forecaster seeking to minimize their expected loss is to state the forecast they believe to be true.

\subsection{The allocation score is proper}
\label{sec:alloscore_proper}

Our primary decision theoretical procedure, outlined in section \ref{sec:methods.detailed.decisiontheory} of the main text,
uses a decision problem with loss function $s(x,y)$ to define a scoring rule
\begin{align}
S(F,y) := s(x^F,y) \label{eqn:bayes_sr}
\end{align}
where $x^F := \argmin_{x} \Ex_F[s(x,Y)]$ is the Bayes act for $F$ with respect to $s$.
Such scoring rules, which we call \emph{Bayes scoring rules},
are proper by construction since
\begin{align}
\Ex_F [S(F, Y)] &= \Ex_F [ s(x^F, Y) ] \nonumber \\
 &= \mathrm{min}_{x} \Ex_F [ s(x, Y) ] \quad \text{ (by definition of $x^F$)} \\
 &\leq \Ex_F [ s(x^G, Y) ] \label{eqn:dt_proper_key} \\
 &= \Ex_F [ S(G, Y)]. \nonumber
\end{align}

The allocation scoring rule is Bayes and therefore proper.

We note that in the probabilistic forecasting literature (see e.g., \cite{gneiting2011making}, Theorem 3) what we have
termed Bayes scoring rules typically appear via \eqref{eqn:bayes_sr} where $x^F$ is some given functional of $F$ which
can be shown to be \emph{elicitable}, that is, to be the Bayes act for some loss function $s$.
Such a loss function is said to be a \emph{consistent loss (or scoring) function} for the functional $F \mapsto x^F$, and many important
recent results in the literature (e.g., \cite{fisslerziegel2016consistency}) address whether there \emph{exists} any loss
function that is consistent for $x^F$. Our orientation
is different from this insofar as we \emph{begin} by specifying a decision problem and a loss function of subject matter relevance
and use the Bayes act only as a bridge to a proper scoring rule.  Consistency is never in doubt.


\section{Expected shortages}
\label{sec:ex-shortage}

A key feature of loss functions for decision problems used to define quantiles and related scoring rules such as the
CRPS and the WIS (see e.g., \cite{gneiting2011quantiles}, \cite{jose2009evaluating},
and \cite{royset2022optimization}, sections 1.C and 3.C), as well as the allocation loss function presented in this work,
is the presence of a \emph{shortage}:
the amount $\max\{0,y-x\}$ by which a resource demand
$y$ exceeds a supply decision variable $x$, which, for convenience, we write as $(y-x)_{+}$. In particular, a quantile at
probability level $\alpha$ of a distribution $F$ on $\mathbb{R}^1$ (which we assume to have a well-defined density $f(x)$)
is a Bayes act for the loss function
\[
l(x,y) = Cx + L(y-x)_{+}
\]
where $\alpha = 1-C/L$ and $C$ and $L$ can be interpreted as the cost per unit of a resource (such as medicine) and the loss
incurred when a unit of demand (such as illness) cannot be met due to the shortage $(y-x)_{+}$.  This follows because a
Bayes act, as a minimizer of $\Ex_F[l(x,Y)]$, must also be a vanishing point of the derivative
\begin{align}
\dby{}{x} \Ex_F\left[l(x,Y)\right] &= \Ex_F\left[\dby{}{x}l(x,Y)\right] \nonumber\\
&= C + L\Ex_F\left[\dby{}{x}(Y-x)_+\right] \nonumber\\
&= C - L\Ex_F\left[\mathbf{1}\{Y > x\}\right] \nonumber\\
&= C + L(F(x) - 1), \label{eqn:q_deriv}
\end{align}
so that $1-C/L = F(x)$.
The formula $\dby{}{x}\Ex_F\left[(Y-x)_+\right] = F(x) - 1$ for the derivative of the shortage,
used above in \eqref{eqn:q_deriv}, can be obtained from an application of the ``Leibniz Rule'':
\begin{align}
	\frac{d}{dx} \Ex_F [(Y-x)_{+}] &= \frac{d}{dx} \int_{x}^{\infty} (y-x) f_Y(y)dy \nonumber\\
	&= \int_{x}^{\infty} \frac{d}{dx}(y-x) f_Y(y)dy - (x-x) f_Y(x) = -\int_{x}^{\infty} f_Y(y)dy = F(x)-1. \label{eqn:shortage_deriv}
\end{align}
Note that more care is required when $F$ does not have a density.
We will also use this result below in deriving the Bayes act for the allocation loss.

\section{Allocation Bayes acts as vectors of marginal quantiles.}
\label{sec:bayes-quantiles}

Here we study the form of the Bayes act for the allocation problem (AP) (equation \eqref{eqn:loss_fn} in section \ref{sec:methods.detailed.specific_allocation}) of the text:
\begin{align}
    \underset{0 \leq x}{\mathrm{minimize}}\,\, \mathbb{E}_{F} [s_A(x, Y)]= \sum_{i=1}^{N} L \cdot \mathbb{E}_{F_i}[(Y_i - x_i)_{+}]
     \text{ subject to }
     \, \sum_{i=1}^N x_i = K, \label{AP}
\end{align}
where the marginal forecasts $F_i$ for $i=1,\dots,N$ represent forecasts for $N$ distinct locations.
We show that the Bayes act $x^{F,K} = (x_1^{F,K},\ldots,x_N^{F,K})$ for a forecast $F$ and resource constraint level $K$
is a vector of quantiles of the marginal forecast distributions $F_i$ at a single probability level
$\tau^{F,K}$, that is, $x_i^{F,K} = q_{F_i,\tau^{F,K}}$. An immediate consequence used in the examples in Section \ref
{sec:methods.overview} in the main text is that if $F_i = \mathrm{Exp}(1/\sigma_i)$ for all $i$, then the Bayes act is
proportional to $(\sigma_1,\ldots,\sigma_N)$, since $q_{\mathrm{Exp}(1/\sigma),\tau} = -\sigma \log(1-\tau)$.

In order for $x^{\star} \in \mathbb{R}^N_{+}$ to solve the AP it must be true that reallocating $\delta > 0$ units of the resource from location $i$ to location $j$ will lead to a net increase in expected shortage --- in other words, the reallocation increases the expected shortage in location $i$ is at least as much as it decreases the expected shortage in location $j$:
\begin{align*}
&\mathbb{E}_{F_i}[(Y_i - (x^{\star}_i - \delta))_{+}] - \mathbb{E}_{F_i}[(Y_i - x^{\star}_i)_{+}]
\text{ (increase in $i$) } \nonumber \\
&\qquad \geq
\mathbb{E}_{F_j}[(Y_j - x^{\star}_j)_{+}] - \mathbb{E}_{F_j}[(Y_j - (x^{\star}_j + \delta))_{+}]
\text{ (decrease in $j$) }.
\end{align*}

Dividing by $\delta$ and letting $\delta \searrow 0$, this implies from
\eqref{eqn:shortage_deriv} that
\begin{align}
1-F_i(x^{\star}_i) &= -\frac{d}{dx_i}\mathbb{E}_{F_i}[(Y_i - x^{\star}_i)_{+}] \nonumber \\
&= \lim_{\delta \searrow 0} \frac{1}{\delta}
\left\{\mathbb{E}_{F_i}[(Y_i - (x^{\star}_i - \delta))_{+}] - \mathbb{E}_{F_i}[(Y_i - x^{\star}_i)_{+}]\right\}
\text{ (increase in $i$) } \nonumber \\
&\geq
\lim_{\delta \searrow 0} \frac{1}{\delta}
\left\{\mathbb{E}_{F_j}[(Y_j - x^{\star}_j)_{+}] - \mathbb{E}_{F_j}[(Y_j - (x^{\star}_j + \delta))_{+}]\right\}
\text{ (decrease in $j$) } \nonumber \\
 &= -\dby{}{x_j}\mathbb{E}_{F_j}[(Y_j - x^{\star}_j)_{+}] = 1-F_j(x^{\star}_j) \label{eqn:ASoptimal1}
\end{align}

Note that negative derivatives appear because our optimality condition addresses how a \emph{decrease} in resources will
\emph{increase} the expected shortage in $i$ and vice versa in $j$. Since \eqref{eqn:ASoptimal1} also holds with $i$ and $j$
reversed, a number $\lambda$ (a \emph{Lagrange multiplier}) exists such that
$L(1-F_k(x^{\star}_k)) = \lambda$ for all $k \in 1,\ldots,N$.
(We scale by $L$ to facilitate possible future interpretations of $\lambda$ in terms of the partial derivatives
of $\mathbb{E}_{F} [s_A(x, Y)]$.)
That is, $x^{\star}_k$ is a quantile $q_{\tau,F_k}$ for
$\tau = 1 - \lambda/L$. The value of $\tau$ is then determined by the constraint equation
\begin{align}
\sum_{i=1}^N q_{\tau,F_i} = K. \label{eqn:quantiles-sum-to-K}
\end{align}
It is important to note that $\tau$ depends on $F$ and $K$ and is \emph{not} a fixed parameter
of the allocation scoring rule.

\section{Numerical computation of allocation Bayes acts}
\label{sec:numeric}

To compute an allocation score $S_A(F,y;K) := s_A(x^{F,K},y)$, we require numerical values for a
Bayes act solving the AP \eqref{AP} --- that is, we must find the specific resource allocations for each location that are determined by the forecast $F$ under the resource constraint $K$.
Assuming we have reliable means of calculating quantiles $q_{\alpha,F_i}$
of the marginal forecasts $F_i$,
these allocations are given by $q_{\tau^{\star},F_i}$ where $\tau^{\star}$ solves the equation \eqref{eqn:quantiles-sum-to-K}.
However, this equation is not analytically tractable and we must resort to a numerical method
for finding an approximation $\tilde{\tau}$ of $\tau^{\star}$.

We have implemented an iterative bisection method that makes use of the fact that $\sum_{i=1}^N q_{\tau,F_i}$
is an increasing function of $\tau$.
The algorithm begins with an initial search interval $[\tau_{L,1}, \tau_{U,1}]$ (such as $[0,\max_{i}F_i(K)]$) that clearly contains
the solution $\tau^{\star}$.
% This can be confirmed by verifying that the resource allocations corresponding to the lower endpoint of the search interval do not exceed the resource constraint ($\sum_{i=1}^N q_{\tau_L,F_i} \leq K$) and the resource allocations corresponding to the upper endpoint match or exceed the available resources ($\sum_{i=1}^N q_{\tau_U,F_i} \geq K$).
At each step $j$ of the algorithm, we evaluate the total allocation $\sum_{i=1}^N q_{\tau_{M,j},F_i}$ at the midpoint of the search interval,
$\tau_{M,j} = \frac{1}{2}(\tau_{L,j} + \tau_{U,j})$ and continue the search on the narrowed sub-interval
\begin{align}
[\tau_{L,j+1},\tau_{U,j+1}] =
\begin{cases}
[\tau_{L,j}, \tau_{M,j}] & \text{if } \sum_{i=1}^N q_{\tau_{M,j},F_i} \geq K \\
[\tau_{M,j}, \tau_{U,j}] & \text{if } \sum_{i=1}^N q_{\tau_{M,j},F_i} < K.
\end{cases} \nonumber
\end{align}
% We then narrow the search to the sub-interval that contains the solution:
% \begin{itemize}
%   \item If $\sum_{i=1}^N q_{\tau_{M},F_i} \geq K$, we continue the search on the interval $[\tau_L, \tau_M]$.
%   \item If $\sum_{i=1}^N q_{\tau_M, F_i} \leq K$, we continue the search on the interval $[\tau_M, \tau_U]$.
% \end{itemize}
This search continues until $\tau_{U,j+1} < (1+\varepsilon)\tau_{L,j+1}$ for a suitably small $\varepsilon>0$.
We have implemented this procedure along with the resulting score computations in the
R package \verb`alloscore` \citep{gerding-alloscore} which provided all allocation score values used in the analysis of section \ref{sec:application}
in the main text.

Subtleties can arise when the forecast
densities $f_i$ vanish or are very small, in which case quantiles are non-unique or highly variable near a probability level,
leading to ambiguity or numerical instabilities{} in the evaluation of $\sum_{i=1}^N q_{\tau,F_i}$. Additionally, if point masses are present in any of the $F_i$,
\eqref{eqn:quantiles-sum-to-K} will not have a unique solution for some discrete set of constraint levels $K$.
We have adopted conventions for detecting such levels and enforcing consistency in score calculations
near them. Through extensive experimentation, we have determined that these conditions seem to address these challenges with the forecasts we are working with, but we leave a more rigorous approximation error analysis for later work.

\section{Computing allocations from finite quantile forecast representations}
\label{sec:distfromq}

In section \ref{sec:application} of the manuscript, we used the allocation score to evaluate forecasts of COVID-19 hospitalizations that have been submitted to the US COVID-19 Forecast Hub. These forecasts are submitted to the Hub using a set of 23 quantiles of the forecast distribution at the 23 probability levels in the set $\mathcal{T} = \{0.01, 0.025, 0.05, 0.1, 0.15, \ldots, \allowbreak 0.9, 0.95, 0.975, 0.99\}$, which specify a predictive median and the endpoints of central $(1 - \alpha) \times 100\%$ prediction intervals at levels $\alpha = 0.02, 0.05, 0.1, 0.2, \allowbreak 0.3, 0.4, 0.5, 0.6, \allowbreak 0.7, 0.8, 0.9$. For a given week and target date, we use $q_{i,k}$ to denote the submitted quantiles for location $i$ and probability level $\tau_k \in \mathcal{T}$, $k = 1, \ldots, 23$.

In the event that there is some $k \in \{1, \ldots, 23\}$ for which $\sum_i q_{i,k} = K$, i.e., the provided predictive quantiles at level $\tau_k$ sum across locations to the resource constraint $K$, the solution to the allocation problem is given by those quantiles. However, generally this will not be the case; the optimal allocation will typically be at some probability level $\tau^\star \notin \mathcal{T}$.

To address this situation and support the numerical allocation algorithm outlined in section \ref{sec:numeric}, we need a mechanism to approximate the full cumulative distribution functions $F_i$, $i = 1, \ldots, N$ based on the provided quantiles. We have developed functionality for this purpose in the \verb`distfromq` package for R.\citep{ray-distfromq} This functionality represents a distribution as a mixture of discrete and continuous parts, and it works in two steps:
\begin{enumerate}
  \item Identify a discrete component of the distribution consisting of zero or more point masses, and create an adjusted set of predictive quantiles for the continuous part of the distribution by subtracting the point mass probabilities and rescaling.
  \item For the continuous part of the distribution, different approaches are used on the interior and exterior of the provided quantiles:
  \begin{enumerate}
    \item On the interior, a monotonic cubic spline interpolates the adjusted quantiles representing the continuous part of the distribution.
    \item A location-scale parametric family is used to extrapolate beyond the provided quantiles. The location and scale parameters are estimated separately for the lower and upper tails so as to obtain a tail distribution that matches the two most extreme quantiles in each tail. In this work, we use normal distributions for the tails.
  \end{enumerate}
\end{enumerate}
The resulting distributional estimate exactly matches all of the predictive quantiles provided by the forecaster. We use the cumulative distribution function resulting from this procedure as an input to the allocation score algorithm.

We refer the reader to the \verb`distfromq` documentation for further detail.\citep{ray-distfromq}

% \begin{enumerate}
%   \item First, we handle settings where the provided quantiles imply the existence of one or more point masses. Specifically, if there are distinct probability levels $\tau_k < \tau_{k^\prime}$ that have the same quantiles, $q_{l,k} = q_{l, k^\prime}$, the distribution contains a point mass at $q_{l,k}$. We split into three cases depending on the number of distinct provided quantiles:
%   \begin{enumerate}
%     \item If all provided quantiles are equal to each other, we infer that the distribution consists of a single point mass at that quantile value.
%     \item If there are two distinct quantiles across all of the probability levels $\tau_k \in \mathcal{T}$, our estimated distribution consists of a mixture of two point masses. The probability assigned to the point mass at $q$ is proportional to $\tau_q^\max - \tau_q^\min$, where
%     $$\tau_q^\max = \begin{cases}
%       \max_{\{\}} \tau_k
%     \end{cases}$$ is the largest probability level $\tau_k$ for which $q_{l,k} = q$, and $\tau_q^\min$ is defined similarly.
%     \item Otherwise, our final estimate will consist of a mixture of a discrete distribution with point masses at the duplicated quantiles and a continuous distribution elsewhere. In this step, we  In this case, the discrete distribution has point mass probabilities calculated as $d_q = \tau_q^\max - \tau_q^\min$, where $\tau_q^\max$ and $\tau_q^\min$ are defined as in the previous point.
%   \end{enumerate}
% \end{enumerate}


\section{Propriety of parametric approximation} % (fold)
\label{sec:propriety_of_parametric_approximation}

In practice, open forecasting exercises are generally not able to collect a perfect description of the forecast distribution $F$ other than in simple settings such as for a categorical variable with a relatively small number of categories. In settings where the outcome being forecasted is a continuous quantity (such as the proportion of outpatient doctor visits where the patient has influenza-like illness) or a count (such as influenza hospitalizations), forecasting exercises have therefore resorted to collecting summaries of a forecast distribution such as bin probabilities or predictive quantiles.
In this section, we address two practical concerns raised by this. First, we discuss conditions under which it is possible to calculate the allocation score when only summaries of a forecast distribution are recorded in a submission to a forecast hub. Second, we show that a post hoc attempt to compute the allocation score based on submitted predictive quantiles may in fact compute an alternative score that is not proper.

\subsection{Propriety when scoring methods are announced prospectively}

We consider a setting where a forecasting exercise (such as a forecast hub) pre-specifies that forecasts will be represented using a parametric family of forecast distributions $G_\theta(y)$, and the task of the forecaster is to select a particular parameter value $\theta$. We use $\mathcal{P}$ to denote the collection of all distributions $G_\theta$ in the given parametric family. For instance, it has recently been proposed that mixture distributions could be used to represent forecast distributions \citep{wadsworth2023mixture}. Additionally, we note that the functionality in \verb`distfromq` can be viewed as specifying a parametric family $\mathcal{P}_{\mathrm{dfq}}$ where the parameters $\theta$ of $G_\theta$
are its quantiles at pre-specified probability levels, and where the shape of any $G_\theta \in \mathcal{P}_{\mathrm{dfq}}$ over the full range of its support is entirely controlled by these quantiles.

We find it helpful now to formally distinguish between two decision making problems. The first is the public health decision maker's allocation problem where the task is to select an allocation $x$, with the allocation loss $s_A(x, y) = \sum_{i=1}^N L \cdot \max(0, y_i - x_i)$ as described in section \ref{sec:methods.detailed.specific_allocation} of the main text.
The second is the forecaster's reporting problem where the task is to select parameter values $\theta$ to report. The forecaster's loss is given by
\begin{align}
s_R(\theta, y) = s_A(x^{G_\theta}, y), \label{eqn:forecaster_theta_loss}
\end{align}
where $x^{G_\theta}$ is the Bayes act for the allocation problem under the distribution $G_\theta$. In words, the loss associated with reporting $\theta$ is equal to the loss associated with taking the Bayes allocation corresponding to the distribution $G_\theta$.

Following our usual construction, the Bayes act for the forecast reporting problem is the parameter set that minimizes the forecaster's expected loss. Breaking with our earlier notation for improved legibility, we use $\theta^\star(F)$ to denote this Bayes act:
\begin{align*}
\theta^\star(F) &= \text{argmin}_\theta \Ex_F [s_R(\theta, Y)] \\
&= \text{argmin}_\theta \Ex_F [s_A(x^{G_\theta}, Y)]
\end{align*}

We then arrive at the scoring rule
$$S_R(F, y) = s_R(\theta^\star(F), y) = s_A(x^{G_{\theta^\star(F)}}, y).$$
It follows from the discussion in section \ref{sec:alloscore_proper} that this is a proper scoring rule for $F$.
Although the full forecast distribution $F$ is not available in the forecast submission, the score $S_R(F, y)$ can be calculated from the reported parameter values as long as the forecaster submits the optimal parameters $\theta^\star(F)$.

We emphasize that the forecaster's true predictive distribution $F$ does not need to be a member of the specified parametric family $\mathcal{P}$ for this construction to yield a proper score.
It is, however, necessary to specify the parametric family to use and the foundational scoring rule $s_A$ (including any relevant problem parameters such as the resource constraint $K$) in advance, so that forecasters can identify the Bayes act parameter set $\theta^\star(F)$ to report.

If the parametric family used to represent forecast distributions is flexible enough, the reporting scoring rule $S_R$ and the allocation score are equivalent in the sense that they will yield the same score for any distribution $F$.
Suppose that for a given resource constraint $K$, for any forecast distribution $F$ it is possible to find a member $G_{\theta^\star}$ of the specified parametric family $\mathcal{P}$ with the same allocation as $F$ (i.e., $x^F = x^{G_{\theta^\star}}$). Then $\theta^\star$ is a Bayes act for the reporting problem since for any other parameter value $\theta$,
\begin{align*}
\Ex_F[s_R(\theta^\star, Y)] &= \Ex_F[ s_A(x^{G_{\theta^\star}}, Y) ] \\
&= \Ex_F[s_A(x^F, Y)]  \quad \text{ (since $x^F = x^{G_{\theta^\star}}$)} \\
&\leq \Ex_F[ s_A(x^{G_\theta}, Y) ]  \quad \text{ (by definition of $x^F$)} \\
&= \Ex_F[ s_R(\theta, Y)].
\end{align*}
It therefore follows that
\begin{align*}
S_R(F, y) &= s_R(\theta^\star, y) \\
&= s_A(x^{G_{\theta^\star}}, y) \\
&= s_A(x^F, y) \\
&= S_A(F, y).
\end{align*}

For the particular choice of the parametric family $\mathcal{P}_{\text{dfq}}$ (i.e., using the \verb`distfromq` package), this flexibility requirement is satisfied. For instance, the forecaster could pick one required quantile level (such as 0.5, for which the corresponding predictions are predictive medians), and set the submitted quantiles of their forecast distribution in each location at that level to be the desired allocations, which sum to $K$ across all locations.
However, this representation of the forecast may be quite different from the actual forecast distribution $F$.
For example, for the actual forecast distribution $F$ the allocations may occur at some quantile level other than 0.5.

As another alternative for practical forecasting exercises, a forecast hub could ask forecasters to directly provide the Bayes allocations associated with their forecasts for one or more specified resource constraints $K$. At the cost of increasing the number of quantities solicited by the forecast hub, this would have several advantages: it would prevent any artificial distortion of the forecast distributions, allow for direct calculation of scores, and narrow the gap between model outputs and public health end users. For this to be feasible, implementations of the allocation algorithm would have to be provided to participating forecasters in the computational languages being used for modeling.

\subsection{Impropriety of post hoc allocation scoring with quantile forecasts}

A \emph{post hoc} evaluation of quantile forecasts that combines the parametric family specified by \verb`distfromq` with the allocation score does not yield the allocation score of the forecast distribution $F$. Instead, it computes an alternative score that is improper. This is because the forecast distribution $F$ and the distribution $G^q \in \mathcal{P}_{\text{dfq}}$ with the same quantiles as $F$ may determine different resource allocations. In our investigations, these discrepancies appear to be relatively minor on the interior of the provided quantiles, but could be severe if the tail extrapolations performed by \verb`distfromq` do not match the tail behavior of $F$ and the allocations are in the tails of the predictive distribution.

We define
$$G^{\star}(F) := \argmin_{G \in \mathcal{P}_{\mathrm{dfq}}} E_{F}[S_A(G, Y)].$$
Since $S_R$ is defined as the Bayes scoring rule for the forecaster's loss \eqref{eqn:forecaster_theta_loss}, $G^{\star}(F)$ coincides
with $G_{\theta^{\star}(F)}$, the distribution in $\mathcal{P}_{\mathrm{dfq}}$ given by the
optimal submission parameters $\theta^{\star}(F)$ for the forecaster with predictive distribution $F$.
In general, $G^q(F)$ and $G^\star(F)$ will be different distributions:  matching $F$ at specific quantiles
does not require $G^q(F)$ to match $F$ at the quantiles for $\tau^{F,K}$ (c.f. \eqref{eqn:quantiles-sum-to-K}),
which would be necessary for it to share $x^F$ as an optimal allocation.

When an analyst attempts a post hoc computation of the allocation score using $G^q(F)$ (implicitly assuming that $G^q(F) = G^\star(F)$), they in fact compute the alternative score
$$\tilde{S}(F, y) = S_A(G^q(F), y) = s_A(x^{G^q(F)}, y).$$
This score is improper because $E_{F}[S_A(G, Y)]$ is minimized by $G^\star(F)$, not $G^q(F)$.
In general, we have
\begin{align}
E_{F}[\tilde{S}(G^\star(F), Y)] &\leq E_{F}[ S_A(G^q(F), Y) ] \label{eqn:tilde_s_improper} \\
  &= E_{F}[\tilde{S}(F, Y)] \nonumber
\end{align}
However, the inequality in \eqref{eqn:tilde_s_improper} will typically be strict. For example, if $F$ has heavy upper tails (such as for a lognormal distribution), but normal distributions are used for tail extrapolations in \verb`distfromq`, then the resource allocations based on the distribution $G^q(F)$ may be quite different from the optimal allocations under the distribution $F$, leading to a strict inequality. This demonstrates that $\tilde{S}$ is improper.

\bibliography{allocation}

\end{document}
